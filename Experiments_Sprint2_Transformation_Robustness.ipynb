{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seasonal-liabilities",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tfs\n",
    "from src.models.utils import download_checkpoint, load_model\n",
    "from src.experiments import *\n",
    "from src.experiments.utils import *\n",
    "from src.visualization import *\n",
    "from src.optimization import *\n",
    "from IPython.display import Image \n",
    "from PIL import Image\n",
    "\n",
    "checkpoint_path = download_checkpoint(\"https://drive.google.com/file/d/19m_SaRNEF7JXHjeyNu26AxgaEQXqpI00\", \"protopnet.pt\")\n",
    "model = load_model('protopnet', checkpoint_path, device=\"cpu\")\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_base = tfs.Compose([\n",
    "    tfs.ToPILImage(),\n",
    "    tfs.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n",
    "    tfs.RandomRotation((-1, 1)),\n",
    "    tfs.RandomResizedCrop(size=224, scale=(0.99, 1)),\n",
    "    tfs.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-spanish",
   "metadata": {},
   "source": [
    "## Image opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptypes = [(188,1)]\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "normalize = tfs.Normalize(mean, std)\n",
    "transform = tfs.Compose([\n",
    "    tfs.Resize(size=(img_size, img_size)),\n",
    "    tfs.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "input_image = Image.open(\"data/train_cropped/189.Red_bellied_Woodpecker/Red_Bellied_Woodpecker_0002_180879.jpg\")\n",
    "input_tensor = transform(input_image)\n",
    "display(tfs.ToPILImage()(input_tensor))\n",
    "\n",
    "image = visualize_prototypes(model, ptypes, optimization_steps=100, input_tensor=input_tensor, transforms=transforms_base)\n",
    "\n",
    "pilimg = tfs.ToPILImage()(image)\n",
    "display(pilimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open(\"data/train_cropped/189.Red_bellied_Woodpecker/Red_Bellied_Woodpecker_0002_180879.jpg\")\n",
    "input_tensor = transform(input_image)\n",
    "display(tfs.ToPILImage()(input_tensor))\n",
    "\n",
    "image = visualize_prototypes(model, ptypes, optimization_steps=100, input_tensor=input_tensor)\n",
    "\n",
    "pilimg = tfs.ToPILImage()(image)\n",
    "display(pilimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-pitch",
   "metadata": {},
   "source": [
    "## Noise opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptypes = [(188,1)]\n",
    "\n",
    "def before_optim_step(t):\n",
    "    tt = torch.clamp(t, 0, 1)\n",
    "    t.data = tfs.GaussianBlur(7, 2)(tt).data\n",
    "\n",
    "size = (3, 224, 224)\n",
    "input_tensor = torch.randn(size)\n",
    "\n",
    "image = visualize_prototypes(model, ptypes, optimization_steps=100, input_tensor=input_tensor,\n",
    "                             before_optim_step=before_optim_step, optimizer_kwargs={'lr': 0.2}, transforms=transforms_base)\n",
    "\n",
    "pilimg = tfs.ToPILImage()(image)\n",
    "display(pilimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptypes = [(188,1)]\n",
    "\n",
    "def before_optim_step(t):\n",
    "    tt = torch.clamp(t, 0, 1)\n",
    "    t.data = tfs.GaussianBlur(7, 2)(tt).data\n",
    "\n",
    "size = (3, 224, 224)\n",
    "input_tensor = torch.randn(size)\n",
    "\n",
    "image = visualize_prototypes(model, ptypes, optimization_steps=100, input_tensor=input_tensor,\n",
    "                             before_optim_step=before_optim_step, optimizer_kwargs={'lr': 0.2})\n",
    "\n",
    "pilimg = tfs.ToPILImage()(image)\n",
    "display(pilimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-landing",
   "metadata": {},
   "source": [
    "## Octaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-cologne",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptypes = [(188,1)]\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "normalize = tfs.Normalize(mean, std)\n",
    "transform = tfs.Compose([\n",
    "    tfs.Resize(size=(img_size, img_size)),\n",
    "    tfs.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "def before_optim_step(t):\n",
    "    tt = torch.clamp(t, 0, 1)\n",
    "    t.data = tfs.GaussianBlur(7, 2)(tt).data\n",
    "\n",
    "input_image = Image.open(\"data/train_cropped/189.Red_bellied_Woodpecker/Red_Bellied_Woodpecker_0002_180879.jpg\")\n",
    "input_tensor = transform(input_image)\n",
    "display(tfs.ToPILImage()(input_tensor))\n",
    "\n",
    "image = visualize_prototypes_octaves(model, ptypes, optimization_steps=1000, input_tensor=input_tensor,\n",
    "                             before_optim_step=before_optim_step, optimizer_kwargs={'lr': 0.2})\n",
    "\n",
    "pilimg = tfs.ToPILImage()(image)\n",
    "display(pilimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-blanket",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
